{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "get_ipython().magic('matplotlib inline')\n",
    "from scipy.ndimage.measurements import label\n",
    "import findLaneLines\n",
    "findLaneLines.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(16, 16)):\n",
    "    return cv2.resize(img, size).ravel() \n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "def color_hist(imgch1,imgch2,imgch3, nbins=32):\n",
    "    ch1 = np.histogram(imgch1, bins=nbins, range=(0, 256))[0]#We need only the histogram, no bins edges\n",
    "    ch2 = np.histogram(imgch2, bins=nbins, range=(0, 256))[0]\n",
    "    ch3 = np.histogram(imgch3, bins=nbins, range=(0, 256))[0]\n",
    "    hist = np.hstack((ch1, ch2, ch3))\n",
    "    return hist\n",
    "# Define a function to compute HOG features \n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True: # Call with two outputs if vis==True to visualize the HOG\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:      # Otherwise call with one output\n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "# Define a function to extract features from a list of images\n",
    "def img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel, spatial_size=(32, 32)):\n",
    "    #print(spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        #pix_per_cell, cell_per_block, hog_channel, spatial_size)\n",
    "    \n",
    "    file_features = []\n",
    "    feature_image_luv = cv2.cvtColor(feature_image, cv2.COLOR_RGB2LUV)\n",
    "    feature_image_hls = cv2.cvtColor(feature_image, cv2.COLOR_RGB2HLS)\n",
    "    feature_image_hsv = cv2.cvtColor(feature_image, cv2.COLOR_RGB2HSV)\n",
    "    feature_image_gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #print 'spat', spatial_features.shape\n",
    "        file_features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "         # Apply color_hist()\n",
    "        hist_features = color_hist(feature_image_luv[0],feature_image_hls[2],feature_image_hsv[2], nbins=hist_bins)\n",
    "        file_features.append(hist_features)\n",
    "    \n",
    "    if hog_feat == True:\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image_luv.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image_gray[:,:], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "        file_features.append(hog_features)\n",
    "    return np.concatenate(file_features)\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file_p in imgs:\n",
    "        file_features = []\n",
    "        feature_image = cv2.imread(file_p) # Read in each imageone by one\n",
    "        file_features = img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel)\n",
    "        features.append(file_features)\n",
    "        feature_image=cv2.flip(feature_image,1) # Augment the dataset with flipped images\n",
    "        file_features = img_features(feature_image, spatial_feat, hist_feat, hog_feat, hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel)\n",
    "        features.append(file_features)\n",
    "    return features # Return list of feature vectors\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function to draw bounding boxes on an image\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    imcopy = np.copy(img) # Make a copy of the image\n",
    "    for bbox in bboxes: # Iterate through the bounding boxes\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    return imcopy\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=8, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        #print(\"YYYYY\")\n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        #print('Pass-', spatial_size)\n",
    "        features = img_features(test_img, \n",
    "                            spatial_size=spatial_size,spatial_feat=spatial_feat,hist_feat=hist_feat, \n",
    "                            hog_feat=hog_feat, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        #print(features.shape)\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "# A function to show an image\n",
    "def show_img(img):\n",
    "    if len(img.shape)==3: #Color BGR image\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else: # Grayscale image\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap # Return updated heatmap\n",
    "    \n",
    "def apply_threshold(heatmap, threshold): # Zero out pixels below the threshold in the heatmap\n",
    "    heatmap[heatmap < threshold] = 0 \n",
    "    return heatmap \n",
    "\n",
    "def draw_labeled_bboxes1(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        if (((np.max(nonzerox)-np.min(nonzerox))>50) and ((np.max(nonzeroy)-np.min(nonzeroy))>50)):\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "def find_labeled_bboxes(labels):\n",
    "    # Iterate through all detected cars\n",
    "    bbox_list=[]\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox_list.append(((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy))))\n",
    "        # Draw the box on the image\n",
    "        #if (((np.max(nonzerox)-np.min(nonzerox))>50) and ((np.max(nonzeroy)-np.min(nonzeroy))>50)):\n",
    "            #cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the car boxes\n",
    "    return bbox_list\n",
    "def print_boxes(img,boxes):\n",
    "    for car_number in range(len(boxes)):\n",
    "        # Draw the box on the image\n",
    "        if (((boxes[car_number][1][1]-boxes[car_number][0][1])>60) and ((boxes[car_number][1][0]-boxes[car_number][0][0])>60)):\n",
    "            img=cv2.rectangle(img, boxes[car_number][0], boxes[car_number][1], (0,0,255), 6)    \n",
    "            #print('d1-',boxes[car_number][0],'d2-',boxes[car_number][1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('*vehicles/*/*')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "    if 'non' in image:\n",
    "        notcars.append(image)\n",
    "    else:\n",
    "        cars.append(image)\n",
    "print(len(cars))\n",
    "print(len(notcars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car samples:  17584\n",
      "Notcar samples:  17936\n",
      "(35520, 4736)\n",
      "Using: 8 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 4736\n",
      "23.35 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9837\n"
     ]
    }
   ],
   "source": [
    "color_space = 'RGB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 8  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print ('Car samples: ', len(car_features))\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print ('Notcar samples: ', len(notcar_features))\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "\n",
    "X_scaler = StandardScaler().fit(X) # Fit a per-column scaler\n",
    "scaled_X = X_scaler.transform(X) # Apply the scaler to X\n",
    "print(scaled_X.shape)\n",
    "\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features)))) # Define the labels vector\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "print('Using:',orient,'orientations', pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "svc = LinearSVC(loss='hinge') # Use a linear SVC \n",
    "t=time.time() # Check the training time for the SVC\n",
    "svc.fit(X_train, y_train) # Train the classifier\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4)) # Check the score of the SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_vehicles(image):\n",
    "    t=time.time()\n",
    "    prev_cars = []\n",
    "    windows = []\n",
    "    number_layers = 2\n",
    "    global car_boxes\n",
    "    global frame\n",
    "    global heat_prime\n",
    "    global all_car_boxes\n",
    "    global possible_car_boxes\n",
    "    frame +=1\n",
    "    image=cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    search_layers = [[(700,1280),(400,670),(100,100),(0.75,0.75)],\n",
    "                     [(700,1280),(400,590),(64,64),(0.75,0.75)],\n",
    "                     [(750,1000),(400,510),(30,30),(0.75,0.75)]]\n",
    "    #heat_prime = np.zeros((720,1280))\n",
    "    draw_image = np.copy(image)\n",
    "    if (frame%6 == 1):\n",
    "        possible_car_boxes = []\n",
    "    if (frame%3 == 1):\n",
    "        for n in range(number_layers):\n",
    "            windows += slide_window(image, search_layers[n][0],search_layers[n][1],search_layers[n][2],search_layers[n][3])\n",
    "    \n",
    "        if (len(possible_car_boxes) > 0):\n",
    "            for i in possible_car_boxes:\n",
    "                search_win = (int((650-i[1][1])/3),int((650-i[1][1])/3))\n",
    "                windows += slide_window(image,(i[0][0]-5,i[1][0]),(i[0][1],i[1][1]),search_win,(0.75,0.75))\n",
    "    hot_windows = []\n",
    "    hot_windows += (search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=(32,32), hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat))  \n",
    "    if (len(hot_windows) > 2):\n",
    "        heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "        heat = add_heat(heat, hot_windows)\n",
    "        heat_prime = heat_prime + heat\n",
    "        heat_prime = apply_threshold(heat_prime,3) # Apply threshold to help remove false positives\n",
    "        # Visualize the heatmap when displaying    \n",
    "        poss_labels = label(heat_prime)\n",
    "        possible_car_boxes.extend(find_labeled_bboxes(poss_labels))\n",
    "        \n",
    "    if (frame%6 == 1):\n",
    "        \n",
    "        heat_prime = apply_threshold(heat_prime,5)\n",
    "        labels = label(heat_prime)\n",
    "        heat_prime = np.zeros((720,1280))\n",
    "        if (labels[1] > 0):\n",
    "            all_car_boxes=[]\n",
    "            \n",
    "            all_car_boxes.extend(find_labeled_bboxes(labels))\n",
    "            \n",
    "    if (len(all_car_boxes) > 0):\n",
    "        image = print_boxes(image,all_car_boxes)\n",
    "        \n",
    "    return findLaneLines.lane_detection(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output_final.mp4\n",
      "[MoviePy] Writing video project_video_output_final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [13:34<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output_final.mp4 \n",
      "\n",
      "CPU times: user 18min 28s, sys: 26.2 s, total: 18min 54s\n",
      "Wall time: 13min 34s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "frame = 0\n",
    "car_boxes = []\n",
    "heat_prime = np.zeros((720,1280))\n",
    "all_car_boxes = []\n",
    "possible_car_boxes=[]\n",
    "\n",
    "output_v = 'project_video_output_final.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "clip = clip1.fl_image(find_vehicles)\n",
    "get_ipython().magic('time clip.write_videofile(output_v, audio=False)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
